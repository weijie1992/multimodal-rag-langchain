{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba5cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !brew install poppler tesseract libmagic\n",
    "#install globally\n",
    "#brew install tesseract poppler libmagic\n",
    "# echo 'export PATH=\"/opt/homebrew/bin:$PATH\"' >> ~/.zshrc\n",
    "# source ~/.zshrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3bcbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = os.getenv(\"LANGCHAIN_TRACING_V2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c579b2",
   "metadata": {},
   "source": [
    "### Partition PDF tables, text, and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a354bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/opt/homebrew/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a25e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Check if tesseract is accessible\n",
    "try:\n",
    "    result = subprocess.run([\"tesseract\", \"--version\"], capture_output=True, text=True)\n",
    "    print(\"Tesseract version:\", result.stdout)\n",
    "except FileNotFoundError:\n",
    "    print(\"Tesseract not found in PATH\")\n",
    "\n",
    "# Check PATH\n",
    "import os\n",
    "\n",
    "print(\"Current PATH:\", os.environ.get(\"PATH\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ae03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "output_path = \"./content/\"\n",
    "file_path = output_path + \"attention.pdf\"\n",
    "\n",
    "# Reference: https://docs.unstructured.io/open-source/core-functionality/chunking\n",
    "chunks = partition_pdf(\n",
    "    filename=file_path,\n",
    "    infer_table_structure=True,  # extract tables\n",
    "    strategy=\"hi_res\",  # mandatory to infer tables\n",
    "    extract_image_block_types=[\n",
    "        \"Image\"\n",
    "    ],  # Add 'Table' to list to extract image of tables\n",
    "    # image_output_dir_path=output_path,   # if None, images and tables will saved in base64\n",
    "    extract_image_block_to_payload=True,  # if true, will extract base64 for API usage\n",
    "    chunking_strategy=\"by_title\",  # or 'basic'\n",
    "    max_characters=10000,  # defaults to 500\n",
    "    combine_text_under_n_chars=2000,  # defaults to 0\n",
    "    new_after_n_chars=6000,\n",
    "    # extract_images_in_pdf=True,          # deprecated\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd7833",
   "metadata": {},
   "outputs": [],
   "source": [
    "set([str(type(el)) for el in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d129e327",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b56f7",
   "metadata": {},
   "source": [
    "### an image example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8866468",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = chunks[3].metadata.orig_elements\n",
    "chunk_images = [el for el in elements if \"Image\" in str(type(el))]\n",
    "chunk_images[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccecd194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.documents.elements import Table, CompositeElement, Text, Title\n",
    "\n",
    "tables = []\n",
    "texts = []\n",
    "images = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    # print(chunk)\n",
    "    # print(type(chunk))\n",
    "    # Case 1: Direct Table element (not wrapped in CompositeElement)\n",
    "    if isinstance(chunk, Table):\n",
    "        tables.append(chunk)\n",
    "\n",
    "    # Case 2: CompositeElement (e.g., Title + Text + Table grouped)\n",
    "    elif isinstance(chunk, CompositeElement):\n",
    "        texts.append(chunk)\n",
    "        orig_elements = getattr(chunk.metadata, \"orig_elements\", [])\n",
    "        for el in orig_elements:\n",
    "            if isinstance(el, Table):\n",
    "                tables.append(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c175d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04050e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the images from the CompositeElement objects\n",
    "def get_images_base64(chunks):\n",
    "    images_b64 = []\n",
    "    for chunk in chunks:\n",
    "        if \"CompositeElement\" in str(type(chunk)):\n",
    "            chunk_els = chunk.metadata.orig_elements\n",
    "            for el in chunk_els:\n",
    "                if \"Image\" in str(type(el)):\n",
    "                    images_b64.append(el.metadata.image_base64)\n",
    "    return images_b64\n",
    "\n",
    "\n",
    "images = get_images_base64(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36e864",
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b92046",
   "metadata": {},
   "source": [
    "### Text and Table Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8e0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332992aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "prompt_text = \"\"\"\n",
    "You are an assistant tasked with summarizing tables and text.\n",
    "Give a concise summary of the table or text.\n",
    "\n",
    "Respond only with the summary, no additionnal comment.\n",
    "Do not start your message by saying \"Here is a summary\" or anything like that.\n",
    "Just give the summary as it is.\n",
    "\n",
    "Table or text chunk: {element}\n",
    "\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "# Summary chain\n",
    "model = ChatGroq(temperature=0.5, model=\"llama-3.1-8b-instant\")\n",
    "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n",
    "summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724919fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize text\n",
    "text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 1})\n",
    "\n",
    "# Summarize tables\n",
    "tables_html = [table.metadata.text_as_html for table in tables]\n",
    "table_summaries = summarize_chain.batch(tables_html, {\"max_concurrency\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f1fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdbbf0b",
   "metadata": {},
   "source": [
    "### Image Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ca127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt_template = \"\"\"Describe the image in detail. For context,\n",
    "                  the image is part of a research paper explaining the transformers\n",
    "                  architecture. Be specific about graphs, such as bar plots.\"\"\"\n",
    "\n",
    "# prompt_template = \"\"\"Describe the image in detail. For context,\n",
    "#                   it should be a flow diagram\"\"\"\n",
    "messages = [\n",
    "    (\n",
    "        \"user\",\n",
    "        [\n",
    "            {\"type\": \"text\", \"text\": prompt_template},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": \"data:image/jpeg;base64,{image}\"},\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "chain = prompt | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n",
    "\n",
    "\n",
    "image_summaries = chain.batch(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3301fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f751e3e3",
   "metadata": {},
   "source": [
    "### Create a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac5ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import InMemoryStore, LocalFileStore\n",
    "from langchain.schema.document import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "\n",
    "# The vectorstore to use to index the child chunks\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"multi_modal_rag\",\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    "    persist_directory=\"./chroma_db\",  # This will create a folder on your disk\n",
    ")\n",
    "\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "# store = LocalFileStore(\"./document_store\")  # This will create a folder for documents\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "\n",
    "# The retriever (empty to start)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    id_key=id_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fda53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd53f096",
   "metadata": {},
   "source": [
    "### Loading/inserting into vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc77b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add texts\n",
    "doc_ids = [str(uuid.uuid4()) for _ in texts]\n",
    "summary_texts = [\n",
    "    Document(page_content=summary, metadata={id_key: doc_ids[i]})\n",
    "    for i, summary in enumerate(text_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_texts)\n",
    "retriever.docstore.mset(list(zip(doc_ids, texts)))\n",
    "\n",
    "# Add tables\n",
    "table_ids = [str(uuid.uuid4()) for _ in tables]\n",
    "summary_tables = [\n",
    "    Document(page_content=summary, metadata={id_key: table_ids[i]})\n",
    "    for i, summary in enumerate(table_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_tables)\n",
    "retriever.docstore.mset(list(zip(table_ids, tables)))\n",
    "\n",
    "# Add image summaries\n",
    "img_ids = [str(uuid.uuid4()) for _ in images]\n",
    "summary_img = [\n",
    "    Document(page_content=summary, metadata={id_key: img_ids[i]})\n",
    "    for i, summary in enumerate(image_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_img)\n",
    "retriever.docstore.mset(list(zip(img_ids, images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d218be",
   "metadata": {},
   "source": [
    "### Check In memory store data - 15 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106cfb5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8540ecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the keys currently in the store\n",
    "all_doc_ids = store.yield_keys()\n",
    "\n",
    "# Loop through and fetch each document by its ID\n",
    "for doc_id in all_doc_ids:\n",
    "    docs = store.mget([doc_id])  # Returns a list with the document(s)\n",
    "    print(f\"Document ID: {doc_id}\")\n",
    "    for doc in docs:\n",
    "        print(doc)  # `doc` is a Document object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bccf93",
   "metadata": {},
   "source": [
    "### check Chroma document - 15 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702c6c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = vectorstore.get()\n",
    "index = 0\n",
    "for doc in all_docs[\"documents\"]:\n",
    "    print(\"index is :\", index)\n",
    "    print(doc)\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0f14f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add texts\n",
    "# import pickle\n",
    "\n",
    "# doc_ids = [str(uuid.uuid4()) for _ in texts]\n",
    "# summary_texts = [\n",
    "#     Document(page_content=summary, metadata={id_key: doc_ids[i]})\n",
    "#     for i, summary in enumerate(text_summaries)\n",
    "# ]\n",
    "# retriever.vectorstore.add_documents(summary_texts)\n",
    "# # retriever.docstore.mset(\n",
    "# #     [(doc_ids[i], pickle.dumps(texts[i])) for i in range(len(texts))]\n",
    "# # )\n",
    "# retriever.docstore.mset(list(zip(doc_ids, texts)))\n",
    "\n",
    "# # Add tables\n",
    "# table_ids = [str(uuid.uuid4()) for _ in tables]\n",
    "# summary_tables = [\n",
    "#     Document(page_content=summary, metadata={id_key: table_ids[i]})\n",
    "#     for i, summary in enumerate(table_summaries)\n",
    "# ]\n",
    "# retriever.vectorstore.add_documents(summary_tables)\n",
    "# retriever.docstore.mset(list(zip(table_ids, tables)))\n",
    "# # retriever.docstore.mset(\n",
    "# #     [(table_ids[i], pickle.dumps(tables[i])) for i in range(len(tables))]\n",
    "# # )\n",
    "\n",
    "# # Add image summaries\n",
    "# img_ids = [str(uuid.uuid4()) for _ in images]\n",
    "# summary_img = [\n",
    "#     Document(page_content=summary, metadata={id_key: img_ids[i]})\n",
    "#     for i, summary in enumerate(image_summaries)\n",
    "# ]\n",
    "# retriever.vectorstore.add_documents(summary_img)\n",
    "# retriever.docstore.mset(list(zip(img_ids, images)))\n",
    "# # retriever.docstore.mset(\n",
    "# #     [(img_ids[i], pickle.dumps(images[i])) for i in range(len(images))]\n",
    "# # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32722794",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b079b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35da87fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d9b0fd",
   "metadata": {},
   "source": [
    "### Set number of results to be return, say the top K base on relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1190d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever.search_kwargs = {\"k\": 4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c500ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.search_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfcdb59",
   "metadata": {},
   "source": [
    "### Retriever \n",
    " 1) embed query\n",
    " 2) similarity search over summaries, \n",
    " 3) match actual doc store result\n",
    " 4) Return the Doc store result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d49b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = retriever.invoke(\"who are the authors of the paper?\")\n",
    "docs = retriever.invoke(\"what is multihead attention?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d46436",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63b7f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs[0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf7259",
   "metadata": {},
   "source": [
    "### Print the formatted result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e6f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(str(doc) + \"\\n\\n\" + \"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8a17ad",
   "metadata": {},
   "source": [
    "### RAG PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a7512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from base64 import b64decode\n",
    "\n",
    "def parse_docs(docs):\n",
    "    # print('docs is:',docs)\n",
    "    # print('len of doc is: ',len(docs))\n",
    "    \"\"\"Split base64-encoded images and texts\"\"\"\n",
    "    b64 = []\n",
    "    text = []\n",
    "    for doc in docs:\n",
    "        try:\n",
    "            b64decode(doc)\n",
    "            b64.append(doc)\n",
    "        except Exception as e:\n",
    "            text.append(doc)\n",
    "    return {\"images\": b64, \"texts\": text}\n",
    "\n",
    "\n",
    "def build_prompt(kwargs):\n",
    "    # print('kwargs is: ',kwargs)\n",
    "    docs_by_type = kwargs[\"context\"]\n",
    "    user_question = kwargs[\"question\"]\n",
    "\n",
    "    context_text = \"\"\n",
    "    if len(docs_by_type[\"texts\"]) > 0:\n",
    "        # print('docs_by_type[\"texts\"]', docs_by_type[\"texts\"])\n",
    "        for text_element in docs_by_type[\"texts\"]:\n",
    "            # print('text_element', text_element)\n",
    "            context_text += text_element.text\n",
    "\n",
    "    # print(\"context_text\",context_text)\n",
    "    # construct prompt with context (including images)\n",
    "    prompt_template = f\"\"\"\n",
    "    Answer the question based only on the following context, which can include text, tables, and the below image.\n",
    "    Context: {context_text}\n",
    "    Question: {user_question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_content = [{\"type\": \"text\", \"text\": prompt_template}]\n",
    "\n",
    "    if len(docs_by_type[\"images\"]) > 0:\n",
    "        for image in docs_by_type[\"images\"]:\n",
    "            prompt_content.append(\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            HumanMessage(content=prompt_content),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever | RunnableLambda(parse_docs),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableLambda(build_prompt)\n",
    "    | ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    | StrOutputParser()\n",
    ") \n",
    "\n",
    "chain_with_sources = {\n",
    "    \"context\": retriever | RunnableLambda(parse_docs),\n",
    "    \"question\": RunnablePassthrough(),\n",
    "} | RunnablePassthrough().assign(\n",
    "    response=(\n",
    "        RunnableLambda(build_prompt)\n",
    "        | ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "        | StrOutputParser()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecff393",
   "metadata": {},
   "source": [
    "### Check image function, just for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c27a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke(\"What do the authors mean by 'attention'?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain_with_sources.invoke(\"What do the authors mean by 'attention'?\")\n",
    "\n",
    "print(\"Response:\", response[\"response\"])\n",
    "\n",
    "print(\"\\n\\nContext:\")\n",
    "for text in response[\"context\"][\"texts\"]:\n",
    "    print(text.text)\n",
    "    print(\"Page number: \", text.metadata.page_number)\n",
    "    print(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "for image in response[\"context\"][\"images\"]:\n",
    "    display_base64_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396318ca",
   "metadata": {},
   "source": [
    "### Image helper using raw base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82b8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "def display_base64_image(base64_code):\n",
    "    # Decode the base64 string to binary\n",
    "    image_data = base64.b64decode(base64_code)\n",
    "    # Display the image\n",
    "    display(Image(data=image_data))\n",
    "\n",
    "\n",
    "display_base64_image(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e49512",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_summaries[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
